# ##############################################################
# name: Rust Proxy Scanner (Ultimate & Optimized Version)
# ##############################################################
name: Rust Proxy Scanner (Ultimate)

# Triggers for the workflow
on:
  workflow_dispatch:  # Allows manual triggering
  schedule:
    - cron: '0 * * * *'  # Runs automatically every hour

# Ensures only one instance of this workflow runs at a time
concurrency:
  group: rust-proxy-scan
  cancel-in-progress: true

# Environment variables available to all jobs
env:
  KEEP_DEPLOYMENTS: '1' # Number of recent Cloudflare deployments to keep
  CACHE_FILE: .cachelastbestip.txt # File to cache the last best IP
  RUST_VERSION: stable

jobs:
  # ====================================================================
  # JOB 1: Find the best proxy, update Cloudflare, and trigger deploy
  # ====================================================================
  update-proxies:
    runs-on: ubuntu-latest
    timeout-minutes: 20 # Reduced timeout as caching makes it faster
    outputs:
      bestip: ${{ steps.scan.outputs.bestip }}

    steps:
    # 1. Checkout the repository code
    - name: Checkout repo
      uses: actions/checkout@v4

    # 2. Set up the necessary tools
    - name: Setup environment
      run: |
        sudo apt-get update -y
        sudo apt-get install -y jq curl python3 python3-pip netcat-openbsd
        python3 -m pip install --no-cache-dir requests
    
    # 3. Cache Rust dependencies for ultra-fast builds
    - name: Cache Cargo dependencies
      uses: actions/cache@v4
      with:
        path: |
          ~/.cargo/bin/
          ~/.cargo/registry/index/
          ~/.cargo/registry/cache/
          ~/.cargo/git/db/
          target/
        key: ${{ runner.os }}-cargo-${{ hashFiles('**/Cargo.lock') }}

    # 4. Install the Rust compiler
    - name: Install Rust toolchain
      uses: dtolnay/rust-toolchain@stable
      with:
        toolchain: ${{ env.RUST_VERSION }}

    # 5. Build the scanner program (will be very fast after first run)
    - name: Build Rust project
      run: cargo build --release --locked

    # 6. Run the scanner and find the best IP with the lowest latency
    - name: Run scanner and choose best IP
      id: scan
      run: |
        set -euo pipefail # Exit on any error
        BIN="./target/release/RScanner"
        chmod +x "$BIN" || true
        : > scan.log # Clear previous log
        
        # Run scanner and log output
        if ! $BIN 2>&1 | tee -a scan.log; then
          echo "‚ö†Ô∏è WARN: Scanner failed; attempting to parse partial results or use cache."
        fi
        
        BEST=""
        BEST_LAT=""
        
        # Try to find the best IP from the fresh scan log
        awk '
          BEGIN{IGNORECASE=1}
          /PROXY[[:space:]]+LIVE/ {
            if (match($0, /\(([0-9]+)[[:space:]]*ms\)/, lat)) { latency=lat[1] } else next
            if (match($0, /([0-9]{1,3}(\.[0-9]{1,3}){3})/ , addr)) { ip=addr[1] } else next
            print latency, ip
          }
        ' scan.log | sort -n -k1,1 > candidates.txt || true
        
        if [ -s candidates.txt ]; then
          BEST_LAT=$(awk 'NR==1{print $1}' candidates.txt)
          BEST=$(awk 'NR==1{print $2}' candidates.txt)
          echo "‚úÖ Selected candidate from fresh scan: $BEST (latency: ${BEST_LAT} ms)"
        else
          echo "‚ÑπÔ∏è No candidates parsed from scan.log. Checking cache."
        fi
        
        # If no IP was found, fall back to the cached IP
        if [ -z "$BEST" ] && [ -f "${CACHE_FILE}" ]; then
          BEST="$(tr -d ' \r\n' < ${CACHE_FILE} || true)"
          echo "‚Ü™Ô∏è Using cached BEST IP: $BEST"
        fi
        
        # If still no IP, fail the workflow
        if [ -z "${BEST:-}" ]; then
          echo "‚ùå ERROR: No best candidate found from scan or cache. Aborting."
          exit 1
        fi
        
        # Save the best IP for future runs and output it for next steps
        echo "$BEST" > ${CACHE_FILE}
        echo "bestip=$BEST" >> "$GITHUB_OUTPUT"
        echo "üèÜ Final Scanner result: $BEST"

    # 7. Upload the scan log as an artifact for debugging
    - name: Upload scan.log for debug
      uses: actions/upload-artifact@v4
      with:
        name: scan-log-${{ github.run_id }}
        path: scan.log
        
    # 8. Commit and push the cached IP file to the repository
    - name: Commit & push cache
      run: |
        git config --global user.name "NET Sentinel Bot"
        git config --global user.email "actions@github.com"
        git add ${{ env.CACHE_FILE }}
        # Only commit and push if there are actual changes
        if ! git diff --cached --quiet; then
          git commit -m "chore: Update proxy IP to ${{ steps.scan.outputs.bestip }}"
          git push
        else
          echo "No change in best IP. Nothing to commit."
        fi

    # 9. Update the environment variable in Cloudflare Pages with retry logic
    - name: Update Cloudflare Pages env var
      env:
        CF_ACCOUNT_ID: ${{ secrets.CF_ACCOUNT_ID }}
        CF_API_TOKEN: ${{ secrets.CF_API_TOKEN }}
        CF_PROJECT_NAME: ${{ secrets.CF_PROJECT_NAME }}
        CF_VAR_NAME: ${{ secrets.CF_VAR_NAME }}
        BESTIP: ${{ steps.scan.outputs.bestip }}
      run: |
        set -euo pipefail
        if [ -z "${BESTIP:-}" ]; then
          echo "‚ùå ERROR: BESTIP is empty; aborting Cloudflare update."
          exit 1
        fi
        
        API_URL="https://api.cloudflare.com/client/v4/accounts/${CF_ACCOUNT_ID}/pages/projects/${CF_PROJECT_NAME}"
        JSON_PAYLOAD=$(jq -n \
          --arg var_name "$CF_VAR_NAME" \
          --arg var_value "$BESTIP" \
          '{deployment_configs: {production: {env_vars: {($var_name): {value: $var_value}}}}}')

        echo "Attempting to update Cloudflare variable '${CF_VAR_NAME}' to '${BESTIP}'..."
        
        for i in {1..3}; do
          echo "Attempt $i of 3..."
          RESPONSE=$(curl -s -w "\n%{http_code}" -X PATCH "$API_URL" \
            -H "Authorization: Bearer ${CF_API_TOKEN}" \
            -H "Content-Type: application/json" \
            --data "$JSON_PAYLOAD")
          
          HTTP_CODE=$(echo "$RESPONSE" | tail -n1)
          BODY=$(echo "$RESPONSE" | sed '$d')

          if [ "$HTTP_CODE" -eq 200 ] && [ "$(echo "$BODY" | jq -r '.success')" == "true" ]; then
            echo "‚úÖ Cloudflare variable updated successfully!"
            exit 0
          fi

          echo "‚ö†Ô∏è Attempt $i failed with HTTP status $HTTP_CODE. Retrying in 5 seconds..."
          echo "Response Body: $BODY" | jq .
          sleep 5
        done

        echo "‚ùå ERROR: Failed to update Cloudflare variable after 3 attempts."
        exit 1

    # 10. Trigger a new deployment in Cloudflare Pages with retry logic
    - name: Trigger Cloudflare Pages deploy
      if: success()
      env:
        CF_ACCOUNT_ID: ${{ secrets.CF_ACCOUNT_ID }}
        CF_API_TOKEN: ${{ secrets.CF_API_TOKEN }}
        CF_PROJECT_NAME: ${{ secrets.CF_PROJECT_NAME }}
      run: |
        API_URL="https://api.cloudflare.com/client/v4/accounts/${CF_ACCOUNT_ID}/pages/projects/${CF_PROJECT_NAME}/deployments"
        echo "Attempting to trigger a new deployment..."
        
        for i in {1..3}; do
          echo "Attempt $i of 3..."
          RESPONSE_CODE=$(curl -s -o /dev/null -w "%{http_code}" -X POST "$API_URL" \
            -H "Authorization: Bearer ${CF_API_TOKEN}" \
            -H "Content-Type: application/json")

          if [ "$RESPONSE_CODE" -eq 200 ]; then
            echo "üöÄ New deployment triggered successfully."
            exit 0
          fi
          
          echo "‚ö†Ô∏è Attempt $i failed with HTTP status $RESPONSE_CODE. Retrying in 5 seconds..."
          sleep 5
        done
        
        echo "‚ùå ERROR: Failed to trigger Cloudflare deployment after 3 attempts."
        exit 1

    # 11. Clean up old deployments to avoid hitting Cloudflare limits
    - name: Cleanup old Cloudflare deployments
      if: always() # This step runs even if previous steps fail
      env:
        CF_ACCOUNT_ID: ${{ secrets.CF_ACCOUNT_ID }}
        CF_API_TOKEN: ${{ secrets.CF_API_TOKEN }}
        CF_PROJECT_NAME: ${{ secrets.CF_PROJECT_NAME }}
        KEEP: ${{ env.KEEP_DEPLOYMENTS }}
      run: |
        echo "Fetching list of deployments to clean up..."
        DEPLOYMENTS=$(curl -s -X GET "https://api.cloudflare.com/client/v4/accounts/${CF_ACCOUNT_ID}/pages/projects/${CF_PROJECT_NAME}/deployments" -H "Authorization: Bearer ${CF_API_TOKEN}")
        
        IDS_TO_DELETE=$(echo "$DEPLOYMENTS" | jq -r ".result | sort_by(.created_on) | reverse | .[${KEEP}:] | .[] | .id")

        if [ -z "$IDS_TO_DELETE" ]; then
            echo "No old deployments to delete."
            exit 0
        fi

        for id in $IDS_TO_DELETE; do
            echo "Deleting old deployment: $id"
            curl -s -X DELETE "https://api.cloudflare.com/client/v4/accounts/${CF_ACCOUNT_ID}/pages/projects/${CF_PROJECT_NAME}/deployments/${id}" -H "Authorization: Bearer ${CF_API_TOKEN}" > /dev/null
        done
        echo "‚úÖ Cloudflare cleanup complete."

  # ====================================================================
  # JOB 2: Cleanup workflow runs to keep the Actions history clean
  # ====================================================================
  cleanup-runs:
    runs-on: ubuntu-latest
    needs: update-proxies # Runs after the main job is finished
    if: always() # Runs regardless of whether the main job succeeded or failed
    
    # This job needs permission to delete workflow runs
    permissions:
      actions: write
      
    steps:
      - name: Delete old workflow runs
        uses: Mattraks/delete-workflow-runs@v2
        with:
          token: ${{ github.token }}
          repository: ${{ github.repository }}
          retain_days: 7 # Keep runs for 7 days
          keep_minimum_runs: 5 # Always keep the 5 most recent runs for debugging
