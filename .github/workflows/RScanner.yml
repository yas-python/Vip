name: Rust Proxy Scanner for Workers (Ultimate)

# Triggers for the workflow
on:
  workflow_dispatch: # Allows manual triggering
  schedule:
    - cron: '0 * * * *' # Runs automatically every hour

# Ensures only one instance of this workflow runs at a time
concurrency:
  group: rust-proxy-scan
  cancel-in-progress: true

# Environment variables available to all jobs
env:
  # --- Configuration ---
  CARGO_TERM_COLOR: always
  CACHE_FILE: .cachelastbestip.txt # File to cache the last best IP
  RUST_CACHE_KEY: v1 # Increment this to manually invalidate the Rust cache

jobs:
  # This job finds the best proxy and updates Cloudflare
  update-proxy-secret:
    runs-on: ubuntu-latest
    timeout-minutes: 30
    outputs:
      bestip: ${{ steps.scan.outputs.bestip }}

    steps:
      # 1. Checkout the repository code
      - name: Checkout repo
        uses: actions/checkout@v4

      # 2. Set up the necessary tools
      - name: Setup environment
        run: |
          sudo apt-get update -y
          sudo apt-get install -y jq curl python3 python3-pip netcat-openbsd
          python3 -m pip install --no-cache-dir requests

      # 3. Restore best IP from cache (will be saved automatically at the end of the job)
      - name: Manage Best IP Cache
        uses: actions/cache@v4
        id: ip-cache
        with:
          path: ${{ env.CACHE_FILE }}
          key: rust-proxy-scanner-best-ip-cache

      # 4. Install Rust toolchain and cache dependencies for faster builds
      - name: Install Rust toolchain
        uses: dtolnay/rust-toolchain@stable

      # NOTE: The "Cache not found" warning you see is NORMAL for the first run.
      # The cache is saved at the end of the job, so the warning will disappear on the next run.
      - name: Cache Rust dependencies
        uses: Swatinem/rust-cache@v2
        with:
          key: ${{ env.RUST_CACHE_KEY }}

      # 5. Build the scanner program
      - name: Build Rust project
        run: cargo build --release

      # 6. Run the scanner and find the best IP with the lowest latency
      - name: Run scanner and choose best IP
        id: scan
        run: |
          set -euo pipefail # Exit on any error, making the script more robust
          BIN="./target/release/RScanner"
          chmod +x "$BIN"
          : > scan.log # Clear previous log

          echo "ðŸš€ Starting proxy scan..."
          $BIN 2>&1 | tee -a scan.log || echo "âš ï¸ Scanner exited with a non-zero status. Will try to find proxies in partial results."

          BEST=""
          BEST_LAT=""

          echo "ðŸ” Analyzing scan results..."
          awk '
            BEGIN{IGNORECASE=1}
            /PROXY[[:space:]]+LIVE/ {
              if (match($0, /([0-9]+)[[:space:]]*ms/, lat)) { latency=lat[1] } else next
              if (match($0, /([0-9]{1,3}(\.[0-9]{1,3}){3})/ , addr)) { ip=addr[1] } else next
              print latency, ip
            }
          ' scan.log | sort -n -k1,1 > candidates.txt

          if [ -s candidates.txt ]; then
            BEST_LAT=$(awk 'NR==1{print $1}' candidates.txt)
            BEST=$(awk 'NR==1{print $2}' candidates.txt)
            echo "âœ… Selected best candidate from new scan: $BEST (latency: ${BEST_LAT} ms)"
          else
            echo "ðŸŸ¡ No live proxies found in the new scan. Checking for a cached IP."
          fi

          if [ -z "$BEST" ] && [ -f "${CACHE_FILE}" ]; then
            BEST="$(tr -d ' \r\n' < ${CACHE_FILE})"
            echo "âœ… Using cached best IP: $BEST"
          fi

          if [ -z "${BEST:-}" ]; then
            echo "âŒ FATAL: No best candidate found from scan or cache. Aborting."
            exit 1
          fi

          echo "ðŸ’¾ Saving '$BEST' to cache file and GitHub output."
          echo "$BEST" > ${CACHE_FILE}
          echo "bestip=$BEST" >> "$GITHUB_OUTPUT"

      # 7. Upload the scan log as an artifact for debugging
      - name: Upload scan.log for debug
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: scan-log-${{ github.run_id }}
          path: scan.log

      # 8. Update the secret variable in Cloudflare Workers
      - name: Update Cloudflare Worker Secret
        env:
          CF_ACCOUNT_ID: ${{ secrets.CF_ACCOUNT_ID }}
          CF_API_TOKEN: ${{ secrets.CF_API_TOKEN }}
          CF_WORKER_NAME: ${{ secrets.CF_WORKER_NAME }} # <--- S_E_C_R_E_T required for Workers
          CF_VAR_NAME: ${{ secrets.CF_VAR_NAME }}     # <--- Name of the secret (e.g., PROXYIP)
          BESTIP: ${{ steps.scan.outputs.bestip }}
        run: |
          set -euo pipefail

          # Smart check for all required secrets
          if [ -z "${BESTIP:-}" ]; then
            echo "âŒ ERROR: BESTIP is empty; aborting Cloudflare update."
            exit 1
          fi
          if [ -z "${CF_ACCOUNT_ID:-}" ]; then
            echo "âŒ ERROR: CF_ACCOUNT_ID secret is not set."
            exit 1
          fi
          if [ -z "${CF_API_TOKEN:-}" ]; then
            echo "âŒ ERROR: CF_API_TOKEN secret is not set."
            exit 1
          fi
          if [ -z "${CF_WORKER_NAME:-}" ]; then
            echo "âŒ ERROR: CF_WORKER_NAME secret is not set."
            exit 1
          fi
          if [ -z "${CF_VAR_NAME:-}" ]; then
            echo "âŒ ERROR: CF_VAR_NAME secret is not set."
            exit 1
          fi

          # This is the correct API endpoint for bulk-updating secrets on a Worker
          API_URL="https://api.cloudflare.com/client/v4/accounts/${CF_ACCOUNT_ID}/workers/scripts/${CF_WORKER_NAME}/secrets"

          # Build the JSON Payload. Note: This sets ONE secret.
          # The API expects an array of secret objects.
          JSON_PAYLOAD=$(jq -n \
            --arg var_name "$CF_VAR_NAME" \
            --arg var_value "$BESTIP" \
            '[{ "name": $var_name, "text": $var_value, "type": "secret_text" }]')

          echo "ðŸ“¡ Sending PUT request to Cloudflare API to update Worker secret..."
          echo "Payload: $JSON_PAYLOAD"

          # Use PUT request for this endpoint
          RESPONSE=$(curl -s -w "\n%{http_code}" -X PUT "$API_URL" \
            -H "Authorization: Bearer ${CF_API_TOKEN}" \
            -H "Content-Type: application/json" \
            --data "$JSON_PAYLOAD")

          HTTP_CODE=$(echo "$RESPONSE" | tail -n1)
          BODY=$(echo "$RESPONSE" | sed '$d')

          if [ "$HTTP_CODE" -ne 200 ]; then
            echo "âŒ Error: Cloudflare API returned HTTP status $HTTP_CODE"
            echo "Response Body: $BODY"
            # This check specifically catches the error from your images
            if echo "$BODY" | jq -e '.errors[] | select(.code == 10003)' > /dev/null; then
              echo "ðŸ‘‰ HINT: Error 10003 means 'Missing required url parameter'. Check if your CF_ACCOUNT_ID or CF_WORKER_NAME secrets are correct."
            fi
            exit 1
          fi
          
          echo "âœ… Cloudflare Worker secret '${CF_VAR_NAME}' updated successfully."
          echo "âœ¨ Note: The secret is now available to your Worker. No new deployment is needed."

  # JOB 2: Cleanup workflow runs to keep the Actions history clean
  cleanup-runs:
    runs-on: ubuntu-latest
    needs: update-proxy-secret
    if: always() # Always run this, even if the update job fails
    permissions:
      actions: write # Required to delete workflow runs
    steps:
      - name: Delete old workflow runs
        uses: Mattraks/delete-workflow-runs@v2
        with:
          token: ${{ github.token }}
          repository: ${{ github.repository }}
          retain_days: 0 # Retain runs for 0 days
          keep_minimum_runs: 0 # Keep 0 minimum runs
