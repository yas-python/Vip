# ======================================================================
#  Rust Proxy Scanner (Intelligent & Resilient Edition)
#  Engineered for maximum speed, code quality, and operational reliability.
# ======================================================================
name: Rust Proxy Scanner (Intelligent & Resilient)

# ----------------------------------------------------------------------
#  TRIGGERS
#  Defines when the workflow runs.
# ----------------------------------------------------------------------
on:
  # Allows manual triggering from the GitHub Actions UI.
  workflow_dispatch:
  # Runs automatically at the start of every hour.
  schedule:
    - cron: '0 * * * *'

# ----------------------------------------------------------------------
#  CONCURRENCY & PERMISSIONS
#  Ensures safe execution and follows the principle of least privilege.
# ----------------------------------------------------------------------
concurrency:
  group: rust-proxy-scan
  cancel-in-progress: true

permissions:
  contents: write # Required to commit the updated IP cache file.
  actions: write  # Required to manage and delete old workflow runs.

# ----------------------------------------------------------------------
#  GLOBAL ENVIRONMENT VARIABLES
#  Configuration available to all jobs in this workflow.
# ----------------------------------------------------------------------
env:
  KEEP_DEPLOYMENTS: '1' # Number of recent Cloudflare deployments to retain.
  CACHE_FILE: .cachelastbestip.txt # File to cache the last known best IP as a fallback.
  RUST_VERSION: stable # Defines the Rust toolchain version for consistent builds.

# ======================================================================
#  JOBS
#  A sequence of tasks executed on GitHub-hosted runners.
# ======================================================================
jobs:
  # --------------------------------------------------------------------
  #  JOB 1: BUILD & VERIFY
  #  Compiles the Rust application after passing rigorous quality checks.
  # --------------------------------------------------------------------
  build:
    name: '‚öôÔ∏è Compile & Verify Scanner'
    runs-on: ubuntu-latest
    timeout-minutes: 10

    steps:
    - name: '‚¨áÔ∏è Checkout Repository Code'
      uses: actions/checkout@v4

    - name: 'ü¶Ä Install Rust Toolchain'
      uses: dtolnay/rust-toolchain@master
      with:
        toolchain: ${{ env.RUST_VERSION }}
        components: clippy, rustfmt # Install formatter and linter components.

    - name: 'üß† Cache Rust Dependencies'
      uses: Swatinem/rust-cache@v2
      with:
        # The cache key is designed for high precision. It includes the OS,
        # Rust toolchain version, and hashes of dependency/config files.
        # This ensures the cache is only used when it's guaranteed to be valid.
        key: ${{ runner.os }}-rust-${{ env.RUST_VERSION }}-${{ hashFiles('**/Cargo.lock') }}-${{ hashFiles('**/.rustfmt.toml') }}-${{ hashFiles('**/clippy.toml') }}

    - name: 'üíÖ Check Code Formatting'
      run: cargo fmt --all -- --check

    - name: 'üî¨ Lint Code with Clippy'
      # This step runs the Rust linter to catch common mistakes and improve code quality.
      # The `-D warnings` flag treats all warnings as errors, enforcing a high standard.
      run: cargo clippy --all-targets --release -- -D warnings

    - name: 'üõ†Ô∏è Build Rust Project for Release'
      # The build command runs without `--locked` to automatically update the Cargo.lock
      # file if it's out of sync with Cargo.toml, fixing the original error.
      # For best practice, you should periodically run `cargo update` locally and commit
      # the changes to Cargo.lock.
      run: cargo build --release

    - name: 'üì¶ Archive Scanner Binary'
      uses: actions/upload-artifact@v4
      with:
        name: scanner-binary
        path: target/release/RScanner

  # --------------------------------------------------------------------
  #  JOB 2: SCAN, UPDATE & DEPLOY
  #  Runs the scanner, updates Cloudflare, and commits the result.
  # --------------------------------------------------------------------
  scan_and_update:
    name: 'üì° Scan, Update & Deploy'
    runs-on: ubuntu-latest
    needs: build # This job will only start after the 'build' job succeeds.
    timeout-minutes: 30

    steps:
    - name: '‚¨áÔ∏è Checkout Repository Code'
      uses: actions/checkout@v4

    - name: 'üì• Download Scanner Binary'
      uses: actions/download-artifact@v4
      with:
        name: scanner-binary

    - name: 'üîë Make Scanner Executable'
      run: chmod +x RScanner

    - name: '‚ö° Run Scanner and Find Best IP'
      id: scan
      run: |
        set -euo pipefail # Fail script on any error for robustness.
        echo "::group::üöÄ Starting proxy scan..."
        # Run the scanner, redirecting all output to a log file. The `|| true`
        # ensures this step doesn't fail if the scanner exits with a non-zero code,
        # allowing the result analysis to proceed.
        ./RScanner 2>&1 | tee scan.log || true
        echo "::endgroup::"
        
        echo "::group::üîç Analyzing scan results..."
        # This robust awk command parses the log for live proxies, extracts IPs and latencies,
        # and identifies the IP with the absolute lowest latency.
        BEST_IP_FROM_SCAN=$(awk '
          BEGIN{IGNORECASE=1; best_lat=99999; best_ip=""}
          /PROXY[[:space:]]+LIVE/ && match($0, /\(([0-9]+)[[:space:]]*ms\)/, lat) && match($0, /([0-9]{1,3}(\.[0-9]{1,3}){3})/, addr) {
            if (lat[1] < best_lat) {
              best_lat = lat[1]
              best_ip = addr[1]
            }
          }
          END{
            if (best_ip != "") {
              print best_ip
            }
          }
        ' scan.log)
        echo "::endgroup::"

        BEST_IP=""
        if [[ -n "$BEST_IP_FROM_SCAN" ]]; then
          BEST_IP="$BEST_IP_FROM_SCAN"
          echo "‚úÖ Found best IP from new scan: $BEST_IP"
        else
          echo "‚ö†Ô∏è No live proxy found in current scan. Attempting to fall back to cache."
          if [[ -f "${{ env.CACHE_FILE }}" ]]; then
            BEST_IP=$(cat "${{ env.CACHE_FILE }}")
            echo "‚Ü™Ô∏è Using cached IP: $BEST_IP"
          fi
        fi

        if [[ -z "$BEST_IP" ]]; then
          echo "‚ùå CRITICAL: No best IP could be determined from scan or cache. Aborting."
          exit 1
        fi

        echo "Selected IP for deployment: $BEST_IP"
        echo "$BEST_IP" > "${{ env.CACHE_FILE }}"
        echo "bestip=$BEST_IP" >> "$GITHUB_OUTPUT"

    - name: 'üíæ Commit & Push Cache File'
      id: commit
      run: |
        git config --global user.name "NET Sentinel Bot"
        git config --global user.email "actions@github.com"
        git add ${{ env.CACHE_FILE }}
        # Check if the cache file has actually changed to avoid empty commits.
        if ! git diff --cached --quiet; then
          git commit -m "üåê Proxy Update: Set new IP to ${{ steps.scan.outputs.bestip }}"
          git push
          echo "committed=true" >> "$GITHUB_OUTPUT"
        else
          echo "No change in best IP. Skipping commit."
          echo "committed=false" >> "$GITHUB_OUTPUT"
        fi

    - name: '‚òÅÔ∏è Update Cloudflare Pages Environment Variable'
      env:
        CF_ACCOUNT_ID: ${{ secrets.CF_ACCOUNT_ID }}
        CF_API_TOKEN: ${{ secrets.CF_API_TOKEN }}
        CF_PROJECT_NAME: ${{ secrets.CF_PROJECT_NAME }}
        CF_VAR_NAME: ${{ secrets.CF_VAR_NAME }}
        BESTIP: ${{ steps.scan.outputs.bestip }}
      run: |
        set -euo pipefail
        echo "Updating Cloudflare variable '${CF_VAR_NAME}' to '${BESTIP}'..."
        API_URL="https://api.cloudflare.com/client/v4/accounts/${CF_ACCOUNT_ID}/pages/projects/${CF_PROJECT_NAME}"
        # Use jq to safely construct the JSON payload.
        JSON_PAYLOAD=$(jq -n --arg var_name "$CF_VAR_NAME" --arg var_value "$BESTIP" \
          '{deployment_configs: {production: {env_vars: {($var_name): {value: $var_value}}}}}')
        
        # Make the API call and capture the HTTP status code for validation.
        RESPONSE=$(curl -s -w "\n%{http_code}" -X PATCH "$API_URL" \
          -H "Authorization: Bearer ${CF_API_TOKEN}" -H "Content-Type: application/json" --data "$JSON_PAYLOAD")
        
        HTTP_CODE=$(echo "$RESPONSE" | tail -n1)
        BODY=$(echo "$RESPONSE" | sed '$d')

        if [ "$HTTP_CODE" -ne 200 ] || [ "$(echo "$BODY" | jq -r '.success')" != "true" ]; then
          echo "‚ùå Error updating Cloudflare. HTTP Status: $HTTP_CODE"
          echo "Response Body: $(echo "$BODY" | jq .)"
          exit 1
        fi
        echo "‚úÖ Cloudflare variable updated successfully."

    - name: 'üöÄ Trigger New Cloudflare Pages Deployment'
      # Only trigger a new deployment if the IP was updated OR a new commit was made.
      # This prevents redundant deployments if nothing has changed.
      if: success()
      env:
        CF_ACCOUNT_ID: ${{ secrets.CF_ACCOUNT_ID }}
        CF_API_TOKEN: ${{ secrets.CF_API_TOKEN }}
        CF_PROJECT_NAME: ${{ secrets.CF_PROJECT_NAME }}
      run: |
        echo "Triggering new Cloudflare Pages deployment..."
        curl --fail -s -X POST "https://api.cloudflare.com/client/v4/accounts/${CF_ACCOUNT_ID}/pages/projects/${CF_PROJECT_NAME}/deployments" \
        -H "Authorization: Bearer ${CF_API_TOKEN}" \
        -H "Content-Type: application/json"
        echo "‚úÖ New deployment successfully triggered on Cloudflare."

    - name: 'üìú Upload Scan Log for Debugging'
      # Always upload the scan log, regardless of success or failure, to aid in debugging.
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: scan-log-${{ github.run_id }}
        path: scan.log

  # --------------------------------------------------------------------
  #  JOB 3: HOUSEKEEPING
  #  Cleans up old artifacts to maintain a healthy repository.
  # --------------------------------------------------------------------
  cleanup:
    name: 'üßπ Housekeeping'
    runs-on: ubuntu-latest
    needs: scan_and_update # Ensures cleanup runs after the main logic.
    if: always() # IMPORTANT: This job runs even if previous jobs fail.

    steps:
    - name: 'üóëÔ∏è Delete Old Workflow Runs'
      uses: Mattraks/delete-workflow-runs@v2
      with:
        token: ${{ github.token }}
        repository: ${{ github.repository }}
        retain_days: 1 # Keep runs from the last day.
        keep_minimum_runs: 5 # Always keep the 5 most recent runs.

    - name: '‚òÅÔ∏è Cleanup Old Cloudflare Deployments'
      env:
        CF_ACCOUNT_ID: ${{ secrets.CF_ACCOUNT_ID }}
        CF_API_TOKEN: ${{ secrets.CF_API_TOKEN }}
        CF_PROJECT_NAME: ${{ secrets.CF_PROJECT_NAME }}
      run: |
        echo "Fetching list of Cloudflare deployments..."
        DEPLOYMENTS=$(curl -s -X GET "https://api.cloudflare.com/client/v4/accounts/${CF_ACCOUNT_ID}/pages/projects/${CF_PROJECT_NAME}/deployments" -H "Authorization: Bearer ${CF_API_TOKEN}")
        
        # Use jq to safely parse the JSON and get a list of deployment IDs to delete.
        # It sorts by creation date and skips the number of deployments to keep.
        IDS_TO_DELETE=$(echo "$DEPLOYMENTS" | jq -r ".result | sort_by(.created_on) | reverse | .[${{ env.KEEP_DEPLOYMENTS }}:] | .[] | .id")

        if [[ -z "$IDS_TO_DELETE" ]]; then
            echo "‚úÖ No old deployments to delete."
            exit 0
        fi

        echo "Deleting old deployments..."
        for id in $IDS_TO_DELETE; do
            echo "Deleting deployment ID: $id"
            curl -s -X DELETE "https://api.cloudflare.com/client/v4/accounts/${CF_ACCOUNT_ID}/pages/projects/${CF_PROJECT_NAME}/deployments/${id}" -H "Authorization: Bearer ${CF_API_TOKEN}"
        done
        echo "‚úÖ Cloudflare deployment cleanup complete."

