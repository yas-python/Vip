# Name of the workflow
name: Rust Proxy Scanner (Ultimate)

# Triggers for the workflow
on:
  workflow_dispatch:  # Allows manual triggering
  schedule:
    - cron: '0 */1 * * *'  # Runs automatically every hour

# Ensures only one instance of this workflow runs at a time
concurrency:
  group: rust-proxy-scan
  cancel-in-progress: true

# Environment variables available to all jobs
env:
  KEEP_DEPLOYMENTS: '5' # Number of recent deployments to keep
  CACHE_FILE: .cachelastbestip.txt # File to cache the last best IP

jobs:
  # This job finds the best proxy and updates Cloudflare
  update-proxies:
    runs-on: ubuntu-latest
    timeout-minutes: 30
    outputs:
      bestip: ${{ steps.scan.outputs.bestip }}

    steps:
    # 1. Checkout the repository code
    - name: Checkout repo
      uses: actions/checkout@v4
    
    # 2. Set up the necessary tools
    - name: Setup environment
      run: |
        sudo apt-get update -y
        sudo apt-get install -y jq curl python3 python3-pip netcat-openbsd
        python3 -m pip install --no-cache-dir requests
    
    # 3. Install the Rust compiler
    - name: Install Rust toolchain
      uses: dtolnay/rust-toolchain@stable
    
    # 4. Build the scanner program
    - name: Build Rust project
      run: cargo build --release
    
    # 5. Run the scanner and find the best IP with the lowest latency
    - name: Run scanner and choose best IP
      id: scan
      run: |
        set -euo pipefail # Exit on any error
        BIN="./target/release/RScanner"
        chmod +x "$BIN" || true
        : > scan.log # Clear previous log
        
        # Run scanner and log output
        if ! $BIN 2>&1 | tee -a scan.log; then
          echo "WARN: Scanner failed; attempting to parse partial results or use cache."
        fi
        
        BEST=""
        BEST_LAT=""
        
        # Try to find the best IP from the fresh scan log
        awk '
          BEGIN{IGNORECASE=1}
          /PROXY[[:space:]]+LIVE/ {
            if (match($0, /\(([0-9]+)[[:space:]]*ms\)/, lat)) { latency=lat[1] } else next
            if (match($0, /([0-9]{1,3}(\.[0-9]{1,3}){3})/ , addr)) { ip=addr[1] } else next
            print latency, ip
          }
        ' scan.log | sort -n -k1,1 > candidates.txt || true
        
        if [ -s candidates.txt ]; then
          BEST_LAT=$(awk 'NR==1{print $1}' candidates.txt)
          BEST=$(awk 'NR==1{print $2}' candidates.txt)
          echo "Selected candidate from log: $BEST (lat ${BEST_LAT} ms)"
        else
          echo "No candidates parsed from scan.log. Checking cache."
        fi
        
        # If no IP was found, fall back to the cached IP
        if [ -z "$BEST" ] && [ -f "${CACHE_FILE}" ]; then
          BEST="$(tr -d ' \r\n' < ${CACHE_FILE} || true)"
          echo "Using cached BEST IP: $BEST"
        fi
        
        # If still no IP, fail the workflow
        if [ -z "${BEST:-}" ]; then
          echo "ERROR: No best candidate found from scan or cache. Aborting."
          exit 1
        fi
        
        # Save the best IP for future runs and output it for next steps
        echo "$BEST" > ${CACHE_FILE}
        echo "bestip=$BEST" >> "$GITHUB_OUTPUT"
        echo "Scanner result: $BEST"
    
    # 6. Upload the scan log as an artifact for debugging
    - name: Upload scan.log for debug
      uses: actions/upload-artifact@v4
      with:
        name: scan-log
        path: scan.log
        
    # 7. Commit and push the cached IP file to the repository
    - name: Commit & push cache
      run: |
        git config --global user.name "NET Sentinel Bot"
        git config --global user.email "actions@github.com"
        git add ${CACHE_FILE} || true
        if ! git diff --cached --quiet; then
          git commit -m "Proxy update: $(date -u)"
          git push
        else
          echo "No changes to commit."
        fi

    # 8. Update the environment variable in Cloudflare Pages
    - name: Update Cloudflare Pages env var
      env:
        CF_ACCOUNT_ID: ${{ secrets.CF_ACCOUNT_ID }}
        CF_API_TOKEN: ${{ secrets.CF_API_TOKEN }}
        CF_PROJECT_NAME: ${{ secrets.CF_PROJECT_NAME }}
        CF_VAR_NAME: ${{ secrets.CF_VAR_NAME }}
        BESTIP: ${{ steps.scan.outputs.bestip }}
      run: |
        set -euo pipefail
        if [ -z "${BESTIP:-}" ]; then
          echo "ERROR: BESTIP is empty; aborting Cloudflare update."
          exit 1
        fi
        
        API_URL="https://api.cloudflare.com/client/v4/accounts/${CF_ACCOUNT_ID}/pages/projects/${CF_PROJECT_NAME}"
        
        # This JSON payload correctly targets the 'production' environment variables
        JSON_PAYLOAD=$(jq -n \
          --arg var_name "$CF_VAR_NAME" \
          --arg var_value "$BESTIP" \
          '{deployment_configs: {production: {env_vars: {($var_name): {value: $var_value}}}}}')

        echo "Sending PATCH request to Cloudflare API to update variable..."
        echo "Payload: $JSON_PAYLOAD"
        
        # Make the API call and capture the response and HTTP code
        RESPONSE=$(curl -s -w "\n%{http_code}" -X PATCH "$API_URL" \
          -H "Authorization: Bearer ${CF_API_TOKEN}" \
          -H "Content-Type: application/json" \
          --data "$JSON_PAYLOAD")
        
        HTTP_CODE=$(echo "$RESPONSE" | tail -n1)
        BODY=$(echo "$RESPONSE" | sed '$d')

        # Error handling for the API call
        if [ "$HTTP_CODE" -ne 200 ]; then
          echo "Error: Cloudflare API returned HTTP status $HTTP_CODE"
          echo "Response Body: $BODY"
          exit 1
        fi
        
        SUCCESS=$(echo "$BODY" | jq -r '.success')
        if [ "$SUCCESS" != "true" ]; then
            echo "Error: Cloudflare API reported failure."
            echo "Response Body: $BODY" | jq .
            exit 1
        fi
        
        echo "âœ… Cloudflare variable '${CF_VAR_NAME}' updated successfully to '${BESTIP}'."

    # 9. Trigger a new deployment in Cloudflare Pages
    # This is the correct API equivalent of clicking "Retry Deployment" after a config change.
    - name: Trigger Cloudflare Pages deploy
      if: ${{ success() }}
      env:
        CF_ACCOUNT_ID: ${{ secrets.CF_ACCOUNT_ID }}
        CF_API_TOKEN: ${{ secrets.CF_API_TOKEN }}
        CF_PROJECT_NAME: ${{ secrets.CF_PROJECT_NAME }}
      run: |
        echo "Triggering a new deployment..."
        curl -s -X POST "https://api.cloudflare.com/client/v4/accounts/${CF_ACCOUNT_ID}/pages/projects/${CF_PROJECT_NAME}/deployments" \
        -H "Authorization: Bearer ${CF_API_TOKEN}" \
        -H "Content-Type: application/json"
        echo "ðŸš€ New deployment triggered."

    # 10. Clean up old deployments to avoid hitting Cloudflare limits
    - name: Cleanup old deployments
      if: ${{ always() }} # This step runs even if previous steps fail
      env:
        CF_ACCOUNT_ID: ${{ secrets.CF_ACCOUNT_ID }}
        CF_API_TOKEN: ${{ secrets.CF_API_TOKEN }}
        CF_PROJECT_NAME: ${{ secrets.CF_PROJECT_NAME }}
        KEEP: ${{ env.KEEP_DEPLOYMENTS }}
      run: |
        echo "Fetching list of deployments to clean up..."
        DEPLOYMENTS=$(curl -s -X GET "https://api.cloudflare.com/client/v4/accounts/${CF_ACCOUNT_ID}/pages/projects/${CF_PROJECT_NAME}/deployments" -H "Authorization: Bearer ${CF_API_TOKEN}")
        
        # Get IDs of all deployments except for the most recent 'KEEP' number
        IDS_TO_DELETE=$(echo "$DEPLOYMENTS" | jq -r ".result | sort_by(.created_on) | reverse | .[${KEEP}:] | .[] | .id")

        if [ -z "$IDS_TO_DELETE" ]; then
            echo "No old deployments to delete."
            exit 0
        fi

        for id in $IDS_TO_DELETE; do
            echo "Deleting old deployment: $id"
            curl -s -X DELETE "https://api.cloudflare.com/client/v4/accounts/${CF_ACCOUNT_ID}/pages/projects/${CF_PROJECT_NAME}/deployments/${id}" -H "Authorization: Bearer ${CF_API_TOKEN}"
        done
        echo "âœ… Cleanup complete."
