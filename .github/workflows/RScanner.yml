# Rust Proxy Scanner (Ultimate) - KV Update (final, no-IP-cache, robust)
name: Rust Proxy Scanner (Ultimate) - KV Update

on:
  workflow_dispatch:
  schedule:
    - cron: '0 * * * *' # every hour

concurrency:
  group: rust-proxy-scan-final-plaintext
  cancel-in-progress: true

permissions:
  contents: read
  actions: write

env:
  CARGO_TERM_COLOR: always
  # Note: We intentionally DO NOT use a cache file for IP (per your request).
  RUST_CACHE_KEY: v4
  CF_ENVIRONMENT: production
  SCAN_BINARY: ./target/release/RScanner
  SCAN_LOG: scan.log
  MAX_CF_RETRIES: "5"
  CF_RETRY_BASE_SLEEP: "2"
  SCANNER_TIMEOUT: "600"
  # TOP_N only relevant if you later want to sample among top N; default 1 -> absolute lowest
  TOP_N: "1"

jobs:
  update-proxy-variable:
    name: Build â†’ Scan â†’ Update Cloudflare KV (RScanner â†’ CF REST API)
    runs-on: ubuntu-latest
    timeout-minutes: 45
    outputs:
      bestip: ${{ steps.scan.outputs.bestip }}

    steps:
      - name: Checkout repository (full)
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Install system dependencies
        run: |
          set -euo pipefail
          echo "=> Updating package lists..."
          sudo apt-get update -y
          echo "=> Installing required packages..."
          sudo apt-get install -y jq curl netcat-openbsd build-essential pkg-config libssl-dev ca-certificates coreutils

      - name: Install Rust toolchain (stable)
        uses: dtolnay/rust-toolchain@stable
        with:
          toolchain: stable

      - name: Cache Rust artifacts and registry
        uses: actions/cache@v4
        with:
          path: |
            target
            ~/.cargo/registry
            ~/.cargo/git
          key: rust-cache-${{ env.RUST_CACHE_KEY }}-${{ runner.os }}-${{ hashFiles('**/Cargo.lock') }}
          restore-keys: |
            rust-cache-${{ env.RUST_CACHE_KEY }}-${{ runner.os }}-

      - name: Build Rust project (release)
        run: |
          set -euo pipefail
          echo "=> Starting cargo build --release"
          if ! cargo build --release 2>&1 | tee build-output.log; then
            echo "âŒ Cargo build failed. Showing last 200 lines:"
            tail -n 200 build-output.log || true
            exit 1
          fi
          echo "âœ… Cargo build completed successfully"
          ls -lah target/release/ || true
          if [ -f "${{ env.SCAN_BINARY }}" ]; then
            echo "âœ… Scanner binary exists: ${{ env.SCAN_BINARY }}"
          else
            echo "âŒ ERROR: Scanner binary not found at ${{ env.SCAN_BINARY }}"
            exit 1
          fi

      - name: Run scanner and select best IP (absolute lowest latency, no IP cache)
        id: scan
        timeout-minutes: 15
        run: |
          set -euo pipefail
          echo "=== Scanner execution started (choose absolute lowest latency) ==="
          BIN="${{ env.SCAN_BINARY }}"
          LOG="${{ env.SCAN_LOG }}"
          TIMEOUT="${{ env.SCANNER_TIMEOUT }}"
          TOP_N=${TOP_N:-1}

          : > "$LOG"
          rm -f unsorted_candidates.txt candidates.txt || true
          touch unsorted_candidates.txt candidates.txt

          if [ ! -f "$BIN" ]; then
            echo "âŒ FATAL: Scanner binary not found at $BIN"
            ls -la target/release/ || true
            exit 1
          fi
          chmod +x "$BIN"

          # Run scanner safely and capture exit code; always save output to $LOG
          set +e
          timeout "${TIMEOUT}s" "$BIN" > "$LOG" 2>&1
          SCANNER_EXIT_CODE=$?
          set -e

          if [ $SCANNER_EXIT_CODE -eq 0 ]; then
            echo "âœ… Scanner completed successfully"
          elif [ $SCANNER_EXIT_CODE -eq 124 ]; then
            echo "âš ï¸ Scanner timed out after ${TIMEOUT}s"
          else
            echo "âš ï¸ Scanner exited with code $SCANNER_EXIT_CODE (partial results may exist)"
          fi

          # Parse candidate lines into "latency ip" format (latency in ms)
          awk '
            BEGIN { IGNORECASE=1 }
            /PROXY[[:space:]]+LIVE/ {
              if (match($0, /\(([[:space:]]*[0-9]+)[[:space:]]*ms\)/, m)) {
                latency = m[1] + 0
              } else if (match($0, /\(([[:space:]]*[0-9]+)[[:space:]]*s\)/, s)) {
                latency = (s[1] + 0) * 1000
              } else { next }
              if (match($0, /([0-9]{1,3}(\.[0-9]{1,3}){3})/, ipm)) {
                ip = ipm[1]
                print latency, ip
              }
            }
          ' "$LOG" > unsorted_candidates.txt || true

          # fallback lenient parse if necessary
          if [ ! -s unsorted_candidates.txt ]; then
            grep -iE "PROXY[[:space:]]+LIVE" "$LOG" | \
              grep -oE '([0-9]{1,3}\.){3}[0-9]{1,3}.*\([0-9]+.*\)' | \
              sed -E 's/.*(([0-9]{1,3}\.){3}[0-9]{1,3}).*\(([[:space:]]*[0-9]+)[[:space:]]*ms\).*/\3 \1/' >> unsorted_candidates.txt || true
          fi

          # sanitize: valid numeric latency and IPv4 format
          awk '{ if ($1+0 > 0 && match($2, /^([0-9]{1,3}\.){3}[0-9]{1,3}$/)) print $1, $2 }' unsorted_candidates.txt > unsorted_candidates.filtered.txt || true
          mv unsorted_candidates.filtered.txt unsorted_candidates.txt || true

          # Now sort numeric by latency asc and keep top TOP_N (TOP_N=1 -> absolute lowest)
          if [ -s unsorted_candidates.txt ]; then
            sort -n -k1,1 unsorted_candidates.txt | head -n "${TOP_N}" > candidates.txt || cp unsorted_candidates.txt candidates.txt
          else
            touch candidates.txt
          fi

          CANDIDATES_COUNT=$(wc -l < candidates.txt 2>/dev/null || echo 0)
          echo "=> Found ${CANDIDATES_COUNT} valid candidate IPs (kept top ${TOP_N})"
          echo "=> candidates.txt content:"
          cat candidates.txt || true

          if [ -s candidates.txt ]; then
            # If TOP_N>1, we still select the absolute lowest (first line), since requirement is Ú©Ù…ØªØ± Ù¾ÛŒÙ†Ú¯
            read -r BEST_LATENCY BEST_IP < <(head -n1 candidates.txt) || true
            echo "ðŸŽ¯ Best IP selected (lowest ping): ${BEST_IP} with ${BEST_LATENCY}ms"
          else
            echo "âŒ FATAL: No live proxies found in current scan results (no caching allowed per config)"
            echo "=== Last 200 lines of scanner log for debugging ==="
            tail -n 200 "$LOG" || true
            exit 1
          fi

          # Export result to GitHub Actions outputs
          echo "bestip=${BEST_IP}" >> "$GITHUB_OUTPUT"
          echo "=> Final chosen IP: ${BEST_IP} (latency: ${BEST_LATENCY}ms)"
          echo "âœ… Scanner selection step completed successfully"

      - name: Upload scan.log for debugging (always)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: scan-log-${{ github.run_id }}
          path: ${{ env.SCAN_LOG }}
          retention-days: 7
          if-no-files-found: warn

      - name: Upload candidates file for debugging
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: candidates-${{ github.run_id }}
          path: candidates.txt
          retention-days: 7
          if-no-files-found: ignore

      - name: Install Wrangler CLI (kept for compatibility; not required for KV write)
        run: |
          set -euo pipefail
          echo "=> Installing Wrangler CLI using npm..."
          npm install -g wrangler@latest || true
          wrangler --version || true

      - name: Update Cloudflare KV via Cloudflare REST API (curl) with verification & retries
        id: update-kv
        env:
          CF_API_TOKEN: ${{ secrets.CF_API_TOKEN }}
          CF_ACCOUNT_ID: ${{ secrets.CF_ACCOUNT_ID }}
          CF_KV_NAMESPACE_ID: ${{ secrets.CF_KV_NAMESPACE_ID }}
          CF_VAR_KEY: ${{ secrets.CF_VAR_KEY }}
          BESTIP: ${{ steps.scan.outputs.bestip }}
        run: |
          set -euo pipefail
          echo "=== Cloudflare KV update (REST API) started ==="
          # Required env check
          for var in CF_API_TOKEN CF_ACCOUNT_ID CF_KV_NAMESPACE_ID CF_VAR_KEY BESTIP; do
            if [ -z "${!var}" ]; then
              echo "âŒ ERROR: $var is not set"
              exit 1
            fi
          done
          echo "âœ… Required env vars present"

          API_BASE="https://api.cloudflare.com/client/v4"
          NAMESPACE_ID="${CF_KV_NAMESPACE_ID}"
          ACCOUNT_ID="${CF_ACCOUNT_ID}"
          KEY="${CF_VAR_KEY}"
          VALUE="${BESTIP}"
          AUTH_HEADER="Authorization: Bearer ${CF_API_TOKEN}"

          # 1) Verify namespace exists (list namespaces and check)
          echo "=> Verifying KV namespace exists under account ${ACCOUNT_ID}..."
          ns_list=$(curl -sSf -H "${AUTH_HEADER}" "${API_BASE}/accounts/${ACCOUNT_ID}/storage/kv/namespaces" ) || {
            echo "âŒ Failed to list KV namespaces. Response:"
            curl -s -D - -H "${AUTH_HEADER}" "${API_BASE}/accounts/${ACCOUNT_ID}/storage/kv/namespaces" || true
            exit 1
          }
          if ! echo "$ns_list" | jq -e --arg nsid "$NAMESPACE_ID" '.result[] | select(.id==$nsid)' >/dev/null 2>&1; then
            echo "âŒ ERROR: Namespace ID ${NAMESPACE_ID} not found in account ${ACCOUNT_ID}"
            echo "=> Available namespaces (first 20):"
            echo "$ns_list" | jq -r '.result[] | "\(.id)\t\(.title)"' | head -n 20 || true
            exit 1
          fi
          echo "âœ… Namespace ${NAMESPACE_ID} verified."

          # 2) Put key (use retries)
          put_url="${API_BASE}/accounts/${ACCOUNT_ID}/storage/kv/namespaces/${NAMESPACE_ID}/values/${KEY}"
          attempt=0
          max_attempts=${MAX_CF_RETRIES:-5}
          sleep_base=${CF_RETRY_BASE_SLEEP:-2}

          echo "=> Attempting to PUT key '${KEY}' => '${VALUE}' into namespace ${NAMESPACE_ID}"

          while [ $attempt -lt $max_attempts ]; do
            attempt=$((attempt+1))
            echo "=> PUT attempt $attempt/$max_attempts..."
            http_status=$(curl -s -o /tmp/cf_put_resp -w "%{http_code}" -X PUT \
              -H "Authorization: Bearer ${CF_API_TOKEN}" \
              -H "Content-Type: text/plain" \
              --data-binary "${VALUE}" \
              "${put_url}" || echo "000")

            if [ "$http_status" = "200" ] || [ "$http_status" = "201" ] || [ "$http_status" = "204" ]; then
              echo "âœ… PUT successful (HTTP ${http_status})"
              break
            else
              echo "âš ï¸ PUT returned HTTP ${http_status}"
              if [ -s /tmp/cf_put_resp ]; then
                echo "=> Response body:"
                head -n 200 /tmp/cf_put_resp || true
              fi
              if [ $attempt -lt $max_attempts ]; then
                sleep_seconds=$(( sleep_base * attempt ))
                echo "=> Retrying in ${sleep_seconds}s..."
                sleep $sleep_seconds
              else
                echo "âŒ All PUT attempts failed. Exiting."
                cat /tmp/cf_put_resp || true
                exit 1
              fi
            fi
          done

          # 3) Verify by GET
          echo "=> Verifying stored value with GET..."
          get_url="${API_BASE}/accounts/${ACCOUNT_ID}/storage/kv/namespaces/${NAMESPACE_ID}/values/${KEY}"
          http_status=$(curl -s -o /tmp/cf_get_resp -w "%{http_code}" -H "Authorization: Bearer ${CF_API_TOKEN}" "${get_url}" || echo "000")
          if [ "$http_status" = "200" ]; then
            stored_value=$(cat /tmp/cf_get_resp | tr -d '\r\n\t ')
            if [ "$stored_value" = "$VALUE" ]; then
              echo "âœ… KV verification passed. Value matches: ${stored_value}"
            else
              echo "âš ï¸ KV verification mismatch. Stored:'${stored_value}' Expected:'${VALUE}'"
              echo "=> Forcing success exit but please inspect logs. (You can change this to exit 1 if strict)"
              # If you want to fail the workflow on mismatch, uncomment next line:
              # exit 1
            fi
          else
            echo "âš ï¸ GET returned HTTP ${http_status} â€” could not verify value."
            if [ -s /tmp/cf_get_resp ]; then head -n 200 /tmp/cf_get_resp; fi
            # optionally fail:
            # exit 1
          fi

          echo "bestip=${VALUE}" >> "$GITHUB_OUTPUT"
          echo "âœ… Cloudflare KV REST API update completed."
          echo "=== Final IP in KV: ${VALUE} ==="

      - name: Upload Cloudflare REST API logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: cf-rest-logs-${{ github.run_id }}
          path: /tmp/cf_*.log,/tmp/cf_put_resp,/tmp/cf_get_resp
          retention-days: 7
          if-no-files-found: ignore

  cleanup-runs:
    name: Cleanup old workflow runs (optional)
    runs-on: ubuntu-latest
    needs: update-proxy-variable
    if: always()
    permissions:
      actions: write
      contents: read
    steps:
      - name: Checkout for cleanup
        uses: actions/checkout@v4

      - name: Delete old workflow runs
        uses: Mattraks/delete-workflow-runs@v2
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          repository: ${{ github.repository }}
          retain_days: 0
          keep_minimum_runs: 0

  complete-job:
    name: Complete job
    runs-on: ubuntu-latest
    needs: update-proxy-variable
    if: always()
    steps:
      - name: Workflow execution summary
        run: |
          echo "=== Workflow Execution Summary ==="
          echo "=> Best IP selected: ${{ needs.update-proxy-variable.outputs.bestip }}"
          echo "=> Workflow Status: Complete"
          echo "=> Check artifacts for detailed logs"
