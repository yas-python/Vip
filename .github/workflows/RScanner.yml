# ======================================================================
#  Rust Proxy Scanner (Ultimate & Optimized Edition)
#  Engineered for maximum speed, intelligence, and reliability.
#  This version includes professional CI checks and a more robust build process.
# ======================================================================
name: Rust Proxy Scanner (Professional CI/CD)

# ----------------------------------------------------------------------
#  TRIGGERS
#  Defines when the workflow runs automatically or manually.
# ----------------------------------------------------------------------
on:
  workflow_dispatch:  # Allows manual triggering from the Actions tab
  schedule:
    - cron: '0 * * * *'  # Runs automatically at the start of every hour

# ----------------------------------------------------------------------
#  CONCURRENCY CONTROL
#  Ensures only one instance runs at a time to prevent conflicts.
# ----------------------------------------------------------------------
concurrency:
  group: rust-proxy-scan
  cancel-in-progress: true

# ----------------------------------------------------------------------
#  SECURITY PERMISSIONS
#  Restricts permissions for the GITHUB_TOKEN for enhanced security.
# ----------------------------------------------------------------------
permissions:
  contents: write  # Needed to commit the cache file
  actions: write   # Needed to delete old workflow runs

# ----------------------------------------------------------------------
#  ENVIRONMENT VARIABLES
#  Global variables available to all jobs.
# ----------------------------------------------------------------------
env:
  KEEP_DEPLOYMENTS: '1' # Number of recent Cloudflare deployments to keep
  CACHE_FILE: .cachelastbestip.txt # File to cache the last best IP
  RUST_VERSION: stable # Defines the Rust toolchain version

# ======================================================================
#  JOBS
#  The sequence of tasks to be executed.
# ======================================================================
jobs:
  # --------------------------------------------------------------------
  #  JOB 1: BUILD & VERIFY
  #  Verifies code quality, then compiles the Rust application efficiently.
  # --------------------------------------------------------------------
  build_and_verify:
    name: ‚öôÔ∏è Compile & Verify Scanner
    runs-on: ubuntu-latest
    timeout-minutes: 15 # Increased timeout for extra steps
    
    steps:
    - name: ‚¨áÔ∏è Checkout repository code
      uses: actions/checkout@v4

    - name: ü¶Ä Install Rust toolchain
      uses: dtolnay/rust-toolchain@master
      with:
        toolchain: ${{ env.RUST_VERSION }}
        components: clippy, rustfmt # Install clippy and rustfmt for quality checks

    - name: üß† Cache Rust dependencies
      uses: Swatinem/rust-cache@v2
      with:
        key: ${{ runner.os }}-rust-${{ hashFiles('**/Cargo.lock') }}

    # INTELLIGENT UPGRADE: Check formatting to ensure consistent code style.
    - name: üé® Check Code Formatting
      run: cargo fmt --all -- --check

    # INTELLIGENT UPGRADE: Run Clippy linter to catch common mistakes and improve code quality.
    - name: üî¨ Lint Code with Clippy
      run: cargo clippy --all-targets -- -D warnings
      
    # FIX & AUTOMATION: Build the project. Removed '--locked' to allow Cargo to
    # automatically update the lock file if needed, preventing common CI failures.
    - name: üõ†Ô∏è Build Rust project for release
      run: cargo build --release

    - name: üì¶ Archive scanner binary
      uses: actions/upload-artifact@v4
      with:
        name: scanner-binary
        path: target/release/RScanner

  # --------------------------------------------------------------------
  #  JOB 2: SCAN & UPDATE
  #  Runs the scanner, updates Cloudflare, and commits the result.
  #  This job only runs after the 'build_and_verify' job succeeds.
  # --------------------------------------------------------------------
  scan_and_update:
    name: üì° Scan, Update & Deploy
    runs-on: ubuntu-latest
    needs: build_and_verify # Depends on the build and verify job
    timeout-minutes: 30

    steps:
    - name: ‚¨áÔ∏è Checkout repository code
      uses: actions/checkout@v4

    - name: üì• Download scanner binary
      uses: actions/download-artifact@v4
      with:
        name: scanner-binary

    - name: üîë Make scanner executable
      run: chmod +x RScanner

    - name: ‚ö° Run scanner and find best IP
      id: scan
      run: |
        set -euo pipefail
        echo "::group::üöÄ Starting proxy scan..."
        # PROFESSIONAL UPGRADE: Run the scanner but don't let a crash stop the script immediately.
        # This allows us to still parse the log for any partial results.
        set +e
        ./RScanner 2>&1 | tee scan.log
        SCANNER_EXIT_CODE=${PIPESTATUS[0]}
        set -e
        
        if [ $SCANNER_EXIT_CODE -ne 0 ]; then
          echo "‚ö†Ô∏è Warning: Scanner exited with code $SCANNER_EXIT_CODE. Attempting to find IP from log anyway."
        fi
        echo "::endgroup::"
        
        echo "::group::üîç Analyzing scan results..."
        # This awk command robustly finds the IP with the lowest latency from the log.
        # It looks for lines with "PROXY LIVE", extracts latency in "ms", and finds the IP address.
        awk '
          BEGIN{IGNORECASE=1; best_lat=99999; best_ip=""}
          /PROXY[[:space:]]+LIVE/ && match($0, /\(([0-9]+)[[:space:]]*ms\)/, lat) && match($0, /([0-9]{1,3}(\.[0-9]{1,3}){3})/, addr) {
            if (lat[1] < best_lat) {
              best_lat = lat[1]
              best_ip = addr[1]
            }
          }
          END{
            if (best_ip != "") {
              print best_ip
            }
          }
        ' scan.log > best_ip.txt
        echo "::endgroup::"

        BEST_IP=""
        if [ -s best_ip.txt ]; then
          BEST_IP=$(cat best_ip.txt)
          echo "‚úÖ Found best IP from new scan: $BEST_IP"
        else
          echo "‚ö†Ô∏è No live proxy found in scan. Falling back to cache."
          if [ -f "${{ env.CACHE_FILE }}" ]; then
            BEST_IP=$(cat "${{ env.CACHE_FILE }}")
            echo "‚Ü™Ô∏è Using cached IP: $BEST_IP"
          fi
        fi

        if [ -z "$BEST_IP" ]; then
          echo "‚ùå CRITICAL: No best IP found from scan or cache. Aborting."
          exit 1
        fi

        echo "Selected IP: $BEST_IP"
        echo "$BEST_IP" > "${{ env.CACHE_FILE }}"
        echo "bestip=$BEST_IP" >> "$GITHUB_OUTPUT"

    - name: üíæ Commit & push cache file
      run: |
        git config --global user.name "NET Sentinel Bot"
        git config --global user.email "actions@github.com"
        git add ${{ env.CACHE_FILE }}
        # Commit only if there are changes to the cached IP
        if ! git diff --cached --quiet; then
          git commit -m "üåê Proxy update: $(date -u)"
          git push
        else
          echo "No changes in proxy IP. Skipping commit."
        fi

    - name: ‚òÅÔ∏è Update Cloudflare Pages environment variable
      env:
        CF_ACCOUNT_ID: ${{ secrets.CF_ACCOUNT_ID }}
        CF_API_TOKEN: ${{ secrets.CF_API_TOKEN }}
        CF_PROJECT_NAME: ${{ secrets.CF_PROJECT_NAME }}
        CF_VAR_NAME: ${{ secrets.CF_VAR_NAME }}
        BESTIP: ${{ steps.scan.outputs.bestip }}
      run: |
        set -euo pipefail
        echo "Updating Cloudflare variable '${CF_VAR_NAME}' to '${BESTIP}'..."
        API_URL="https://api.cloudflare.com/client/v4/accounts/${CF_ACCOUNT_ID}/pages/projects/${CF_PROJECT_NAME}"
        JSON_PAYLOAD=$(jq -n --arg var_name "$CF_VAR_NAME" --arg var_value "$BESTIP" \
          '{deployment_configs: {production: {env_vars: {($var_name): {value: $var_value}}}}}')
        
        RESPONSE=$(curl -s -w "\n%{http_code}" -X PATCH "$API_URL" \
          -H "Authorization: Bearer ${CF_API_TOKEN}" -H "Content-Type: application/json" --data "$JSON_PAYLOAD")
        
        HTTP_CODE=$(echo "$RESPONSE" | tail -n1)
        BODY=$(echo "$RESPONSE" | sed '$d')

        if [ "$HTTP_CODE" -ne 200 ] || [ "$(echo "$BODY" | jq -r '.success')" != "true" ]; then
          echo "‚ùå Error updating Cloudflare. HTTP Status: $HTTP_CODE"
          echo "Response: $(echo "$BODY" | jq .)"
          exit 1
        fi
        echo "‚úÖ Cloudflare variable updated successfully."

    - name: üöÄ Trigger new Cloudflare Pages deployment
      if: success()
      env:
        CF_ACCOUNT_ID: ${{ secrets.CF_ACCOUNT_ID }}
        CF_API_TOKEN: ${{ secrets.CF_API_TOKEN }}
        CF_PROJECT_NAME: ${{ secrets.CF_PROJECT_NAME }}
      run: |
        curl --fail -s -X POST "https://api.cloudflare.com/client/v4/accounts/${CF_ACCOUNT_ID}/pages/projects/${CF_PROJECT_NAME}/deployments" \
        -H "Authorization: Bearer ${CF_API_TOKEN}" \
        -H "Content-Type: application/json"
        echo "‚úÖ New deployment triggered on Cloudflare."

    - name: üìú Upload scan log for debugging
      if: always() # Always upload the log, even if a step fails
      uses: actions/upload-artifact@v4
      with:
        name: scan-log
        path: scan.log

  # --------------------------------------------------------------------
  #  JOB 3: CLEANUP
  #  Cleans up old Cloudflare deployments and old workflow runs.
  #  Runs in parallel and always executes, even if other jobs fail.
  # --------------------------------------------------------------------
  cleanup:
    name: üßπ Housekeeping
    runs-on: ubuntu-latest
    needs: scan_and_update # Ensures it runs after the main logic
    if: always() # IMPORTANT: This job runs even if previous jobs fail
    
    steps:
    - name: üóëÔ∏è Delete old workflow runs
      uses: Mattraks/delete-workflow-runs@v2
      with:
        token: ${{ github.token }}
        repository: ${{ github.repository }}
        retain_days: 1 # Keep runs from the last day
        keep_minimum_runs: 5 # Always keep the 5 most recent runs

    - name: ‚òÅÔ∏è Cleanup old Cloudflare deployments
      env:
        CF_ACCOUNT_ID: ${{ secrets.CF_ACCOUNT_ID }}
        CF_API_TOKEN: ${{ secrets.CF_API_TOKEN }}
        CF_PROJECT_NAME: ${{ secrets.CF_PROJECT_NAME }}
      run: |
        echo "Fetching list of deployments..."
        DEPLOYMENTS=$(curl -s -X GET "https://api.cloudflare.com/client/v4/accounts/${CF_ACCOUNT_ID}/pages/projects/${CF_PROJECT_NAME}/deployments" -H "Authorization: Bearer ${CF_API_TOKEN}")
        
        # This jq command filters and selects old deployments for deletion.
        # It sorts by creation date (newest first), skips the ones we want to keep,
        # and then extracts the IDs of the remaining (older) ones.
        IDS_TO_DELETE=$(echo "$DEPLOYMENTS" | jq -r ".result | sort_by(.created_on) | reverse | .[${{ env.KEEP_DEPLOYMENTS }}:] | .[] | .id")

        if [ -z "$IDS_TO_DELETE" ]; then
            echo "No old deployments to delete."
            exit 0
        fi

        echo "Deleting old deployments..."
        for id in $IDS_TO_DELETE; do
            echo "Deleting deployment: $id"
            curl -s -X DELETE "https://api.cloudflare.com/client/v4/accounts/${CF_ACCOUNT_ID}/pages/projects/${CF_PROJECT_NAME}/deployments/${id}" -H "Authorization: Bearer ${CF_API_TOKEN}"
        done
        echo "‚úÖ Cleanup complete."

