# 1. FIX: Added name tag to display 'RScanner' in the Actions list instead of the file path.
name: RScanner

# Triggers: manual + hourly schedule
on:
  workflow_dispatch:
  schedule:
    - cron: '0 * * * *' # every hour

# Ensure only one scan runs at a time
concurrency:
  group: rust-proxy-scan-final-plaintext
  cancel-in-progress: true

# Minimal repo permissions required (we need actions:write to delete runs)
permissions:
  contents: read
  actions: write

env:
  CARGO_TERM_COLOR: always
  CACHE_FILE: .cachelastbestip.txt
  RUST_CACHE_KEY: v4
  TIMEOUT_MINUTES: 30
  CF_ENVIRONMENT: production
  SCAN_BINARY: ./target/release/RScanner
  SCAN_LOG: scan.log
  MAX_CF_RETRIES: "5"
  CF_RETRY_BASE_SLEEP: "2"

jobs:
  update-proxy-variable:
    name: Build → Scan → Update Cloudflare Worker (RScanner)
    runs-on: ubuntu-latest
    timeout-minutes: 30 # <-- FIX 1: Replaced ${{ env.TIMEOUT_MINUTES }} with 30 to fix linter error
    outputs:
      bestip: ${{ steps.scan.outputs.bestip }}

    steps:
      - name: Checkout repository (full)
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Install system deps (jq, curl, build tools, libssl)
        run: |
          set -euo pipefail
          echo "=> apt-get update..."
          sudo apt-get update -y
          echo "=> installing packages..."
          sudo apt-get install -y jq curl netcat-openbsd build-essential pkg-config libssl-dev ca-certificates

      - name: Restore Best IP Cache
        uses: actions/cache@v4
        id: ip-cache
        with:
          path: ${{ env.CACHE_FILE }}
          key: rust-proxy-scanner-best-ip-cache-${{ env.RUST_CACHE_KEY }}-${{ runner.os }}

      - name: Install Rust toolchain (stable)
        uses: actions-rs/toolchain@v1
        with:
          profile: minimal
          toolchain: stable
          override: true

      - name: Cache Rust artifacts & registry
        uses: actions/cache@v4
        with:
          path: |
            target
            ~/.cargo/registry
            ~/.cargo/git
          key: rust-cache-${{ env.RUST_CACHE_KEY }}-${{ runner.os }} # <-- FIX 2: Corrected typo RUSS_CACHE_KEY to RUST_CACHE_KEY

      - name: Build Rust project (release)
        run: |
          set -euo pipefail
          echo "=> cargo build --release (start)"
          if ! cargo build --release 2>&1 | tee build-output.log; then
            echo "❌ cargo build failed. Showing last 200 lines from build-output.log"
            tail -n 200 build-output.log || true
            exit 1
          fi
          echo "✅ cargo build completed."
          echo "Contents of target/release:"
          ls -la target/release || true

      - name: Run scanner and choose best IP
        id: scan
        run: |
          set -euo pipefail
          echo "=== Scanner step start ==="
          BIN="${{ env.SCAN_BINARY }}"
          LOG="${{ env.SCAN_LOG }}"
          CACHE_FILE="${{ env.CACHE_FILE }}"
          : > "$LOG"

          echo "→ Checking scanner binary at $BIN"
          if [ ! -f "$BIN" ]; then
            echo "❌ FATAL: Scanner executable not found at $BIN"
            echo "Listing build dir:"
            ls -la ./target/release || true
            exit 1
          fi

          chmod +x "$BIN" || true
          echo "🚀 Running scanner (output → $LOG). Scanner may exit non-zero; we will still attempt to parse results."
          # Run scanner, redirecting output to log and screen. Don't exit on error here.
          "$BIN" 2>&1 | tee -a "$LOG" || echo "⚠️ Scanner exited with non-zero status; continue to parse log."

          echo "🔍 Parsing scan.log for 'PROXY ... LIVE' lines with latency and IPv4"
          awk '
            BEGIN{IGNORECASE=1}
            /PROXY[[:space:]]+LIVE/ {
              # Extract latency (e.g., 123ms)
              if (match($0, /([0-9]+)[[:space:]]*ms/, lat)) { latency=lat[1] } else next
              # Extract IPv4 address
              if (match($0, /([0-9]{1,3}(\.[0-9]{1,3}){3})/ , addr)) { ip=addr[1] } else next
              print latency, ip
            }
          ' "$LOG" | sort -n -k1,1 > candidates.txt || true

          BEST=""
          BEST_LAT=""

          if [ -s candidates.txt ]; then
            BEST_LAT=$(awk 'NR==1{print $1}' candidates.txt)
            BEST=$(awk 'NR==1{print $2}' candidates.txt)
            echo "✅ Selected best candidate from scan: $BEST (latency ${BEST_LAT} ms)"
          else
            echo "🟡 No live proxies parsed from $LOG. Attempting cache fallback..."
          fi

          # Fallback: cached file
          if [ -z "${BEST:-}" ] && [ -f "${CACHE_FILE}" ]; then
            CAND=$(tr -d ' \r\n' < ${CACHE_FILE} || true)
            echo "🔁 Found cache value: '$CAND'"
            # Validate IP format
            if [[ "$CAND" =~ ^[0-9]{1,3}(\.[0-9]{1,3}){3}$ ]]; then
              BEST="$CAND"
              echo "✅ Using cached IP: $BEST"
            else
              echo "⚠️ Cached file exists but value invalid: '$CAND'. Ignoring."
            fi
          fi

          # Final check for failure
          if [ -z "${BEST:-}" ]; then
            echo "❌ FATAL: No best IP found from scan or cache. Dumping last 200 lines of $LOG for debugging:"
            tail -n 200 "$LOG" || true
            # Exit with a non-zero code to fail the job
            exit 1
          fi

          echo "💾 Persisting best IP to cache file (${CACHE_FILE})"
          echo "$BEST" > ${CACHE_FILE} || true

          # Export output correctly for GitHub Actions
          echo "bestip=${BEST}" >> "$GITHUB_OUTPUT"
          echo "✅ Scanner step complete. bestip=${BEST}"
          echo "=== Scanner step end ==="

      - name: Upload scan.log for debugging (always)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: scan-log-${{ github.run_id }}
          path: ${{ env.SCAN_LOG }}

      - name: Update Cloudflare Worker Variable (service vars) with retries
        env:
          CF_ACCOUNT_ID: ${{ secrets.CF_ACCOUNT_ID }}
          CF_API_TOKEN: ${{ secrets.CF_API_TOKEN }}
          CF_WORKER_NAME: ${{ secrets.CF_WORKER_NAME }}
          CF_VAR_NAME: ${{ secrets.CF_VAR_NAME }}
          BESTIP: ${{ steps.scan.outputs.bestip }}
          CF_ENVIRONMENT: ${{ env.CF_ENVIRONMENT }}
          MAX_RETRIES: ${{ env.MAX_CF_RETRIES }}
          BASE_SLEEP: ${{ env.CF_RETRY_BASE_SLEEP }}
        run: |
          set -euo pipefail
          echo "=== Cloudflare update step start ==="

          # Validate required inputs (Fail-fast if secrets are missing)
          : "${BESTIP:?BESTIP is required from scanner step}"
          : "${CF_ACCOUNT_ID:?CF_ACCOUNT_ID secret is required}"
          : "${CF_API_TOKEN:?CF_API_TOKEN secret is required}"
          : "${CF_WORKER_NAME:?CF_WORKER_NAME secret is required}"
          : "${CF_VAR_NAME:?CF_VAR_NAME secret is required}"
          : "${CF_ENVIRONMENT:?CF_ENVIRONMENT is required (env)}"

          GET_API_URL="https://api.cloudflare.com/client/v4/accounts/${CF_ACCOUNT_ID}/workers/services/${CF_WORKER_NAME}/environments/${CF_ENVIRONMENT}"
          PUT_API_URL="${GET_API_URL}/settings"

          # Helper: retry HTTP request with exponential backoff (highly robust)
          retry_request() {
            local method="$1"
            local url="$2"
            local data="${3:-}"
            local attempt=1
            local max="${MAX_RETRIES:-5}"
            local base_sleep="${BASE_SLEEP:-2}"
            while [ "$attempt" -le "$max" ]; do
              echo "→ Attempt #$attempt: ${method} ${url}"
              if [ -z "$data" ]; then
                response=$(curl -s -w "\n%{http_code}" -X "$method" "$url" -H "Authorization: Bearer ${CF_API_TOKEN}" -H "Content-Type: application/json" ) || response=""
              else
                response=$(curl -s -w "\n%{http_code}" -X "$method" "$url" -H "Authorization: Bearer ${CF_API_TOKEN}" -H "Content-Type: application/json" --data "$data" ) || response=""
              fi
              http_code=$(echo "$response" | tail -n1)
              body=$(echo "$response" | sed '$d' || true)

              if [ -n "$http_code" ] && [ "$http_code" -ge 200 ] && [ "$http_code" -lt 300 ]; then
                echo "→ HTTP $http_code success."
                echo "$body"
                return 0
              else
                echo "⚠️ HTTP $http_code (attempt $attempt). Response body (truncated):"
                echo "$body" | sed -n '1,200p' || true
                if [ "$attempt" -lt "$max" ]; then
                  sleep_seconds=$(( base_sleep ** attempt ))
                  echo "⏳ Sleeping ${sleep_seconds}s before retry..."
                  sleep $sleep_seconds
                fi
              fi
              attempt=$((attempt+1))
            done
            echo "❌ All $max attempts failed for ${method} ${url}"
            return 1
          }

          echo "📡 Fetching current service settings (GET ${GET_API_URL}) with retries..."
          if ! body=$(retry_request "GET" "${GET_API_URL}"); then
            echo "❌ Cloudflare GET failed after retries. Ensure CF_ACCOUNT_ID, CF_WORKER_NAME are correct and CF_API_TOKEN has workers.services:read scopes."
            exit 1
          fi

          # Extract vars and secrets safely
          VARS_JSON=$(echo "$body" | jq -r '.result.settings.vars // {}' 2>/dev/null || echo "{}")
          SECRETS_JSON=$(echo "$body" | jq -r '.result.settings.secrets // {}' 2>/dev/null || echo "{}")

          echo "✅ Current vars retrieved. Preparing updated payload."
          # Use jq to update the specific variable, preserving all others
          UPDATED_VARS=$(echo "$VARS_JSON" | jq --arg name "$CF_VAR_NAME" --arg value "$BESTIP" '. | .[$name] = $value' 2>/dev/null || echo "{}")
          # Construct the final payload for the PUT request
          FINAL_PAYLOAD=$(jq -n --argjson vars "$UPDATED_VARS" --argjson secrets "$SECRETS_JSON" '{ "vars": $vars, "secrets": $secrets }')

          echo "📡 Sending PUT to update service settings (PUT ${PUT_API_URL}) with retries..."
          if ! put_body=$(retry_request "PUT" "${PUT_API_URL}" "$FINAL_PAYLOAD"); then
            echo "❌ Cloudflare PUT failed after retries. Check token scopes (workers.services:edit) and service name."
            # The payload is very large, only log a warning and exit cleanly
            exit 1
          fi

          echo "✅ Cloudflare Worker Variable '${CF_VAR_NAME}' updated successfully in '${CF_ENVIRONMENT}'."
          echo "Cloudflare PUT response (truncated):"
          echo "$put_body" | sed -n '1,200p' || true
          echo "=== Cloudflare update step end ==="

  cleanup-runs:
    name: Cleanup old workflow runs
    runs-on: ubuntu-latest
    needs: update-proxy-variable
    if: always() # Run cleanup even if the main job fails
    permissions:
      actions: write
    steps:
      - name: Delete old workflow runs (retain 0 days / keep 0)
        uses: Mattraks/delete-workflow-runs@v2
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          repository: ${{ github.repository }}
          retain_days: 0
          keep_minimum_runs: 0
